{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AAGjB_ptchlQ",
        "M2uQvW1gctyy",
        "0vwTjXzGc1P6",
        "u4EBAAKbeKes"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT7juhBBcI8m",
        "outputId": "48ccdce0-9fc6-4e5d-a8ff-d14ed6ff76fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=key)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "-JT_hbejcZro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interviewer Prompting"
      ],
      "metadata": {
        "id": "AAGjB_ptchlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interview_prompt = \"\"\"\n",
        "You are an AI interviewer analyzing Prompt Engineering techniques. Answer the following structured questions:\n",
        "\n",
        "Q1: What is Prompt Engineering, and why is it important?\n",
        "Q2: Explain the Interview Approach in Prompt Engineering.\n",
        "Q3: Explain Chain-of-Thought (CoT) prompting and its benefits.\n",
        "Q4: Explain Tree-of-Thought (ToT) prompting and how it differs from CoT.\n",
        "Q5: What are Zero-shot and Few-shot prompting? Compare their applications.\n",
        "Q6: Which technique works best for complex problem-solving, and why?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LDD51AkYch48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain-of-Thought (CoT) Prompting"
      ],
      "metadata": {
        "id": "M2uQvW1gctyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_prompt = \"\"\"\n",
        "Solve the following problem using step-by-step reasoning (Chain-of-Thought).\n",
        "\n",
        "Problem: A farmer has 17 sheep, and all but 9 run away. How many are left?\n",
        "\n",
        "Think step by step before answering.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "heA3QQJncq7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree-of-Thought (ToT) Prompting"
      ],
      "metadata": {
        "id": "0vwTjXzGc1P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tot_prompt = \"\"\"\n",
        "You are an AI that solves problems using a Tree-of-Thought approach.\n",
        "\n",
        "Problem: A company wants to optimize its customer service chatbot.\n",
        "There are three potential solutions:\n",
        "1. Improve NLP understanding.\n",
        "2. Increase response speed.\n",
        "3. Enhance personalization.\n",
        "\n",
        "Break down the pros and cons of each solution in a tree-like structure, then suggest the best choice based on reasoning.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "n8PgvnI8c0_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot Prompting"
      ],
      "metadata": {
        "id": "u4EBAAKbeKes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_prompt = \"\"\"\n",
        "Translate the following English sentence to French:\n",
        "\"The sky is blue and the sun is shining.\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "L4qeVMQ9eL7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few-Shot Prompting"
      ],
      "metadata": {
        "id": "Zv_o2Ls4eVJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = \"\"\"\n",
        "Translate the following English sentences to French:\n",
        "\n",
        "Example 1:\n",
        "English: \"Hello, how are you?\"\n",
        "French: \"Bonjour, comment ça va?\"\n",
        "\n",
        "Example 2:\n",
        "English: \"Where is the nearest train station?\"\n",
        "French: \"Où est la gare la plus proche?\"\n",
        "\n",
        "Now, translate the following:\n",
        "English: \"The sky is blue and the sun is shining.\"\n",
        "French:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "c58igL_LeVd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run all prompts through Gemini\n",
        "responses = {\n",
        "    \"Interview Approach\": model.generate_content(interview_prompt).text,\n",
        "    \"Chain-of-Thought (CoT)\": model.generate_content(cot_prompt).text,\n",
        "    \"Tree-of-Thought (ToT)\": model.generate_content(tot_prompt).text,\n",
        "    \"Zero-Shot Prompting\": model.generate_content(zero_shot_prompt).text,\n",
        "    \"Few-Shot Prompting\": model.generate_content(few_shot_prompt).text,\n",
        "}\n",
        "\n",
        "# Print the results\n",
        "for key, response in responses.items():\n",
        "    print(f\"\\n📝 {key}:\\n{response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "65Efl555ee3d",
        "outputId": "9a5f49d7-bfa0-4072-f01a-5fdc4d491abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Interview Approach:\n",
            "**Q1: What is Prompt Engineering, and why is it important?**\n",
            "\n",
            "Prompt engineering is the art and science of designing effective prompts to elicit desired outputs from large language models (LLMs).  It involves crafting input text in a way that maximizes the likelihood of the LLM generating accurate, relevant, and high-quality responses.  It's important because the quality of the LLM's output is heavily reliant on the quality of the input prompt.  A poorly designed prompt can lead to inaccurate, nonsensical, or biased results, while a well-crafted prompt can unlock the full potential of the LLM, leading to more useful and insightful applications.  In essence, prompt engineering bridges the gap between human intentions and LLM capabilities.\n",
            "\n",
            "\n",
            "**Q2: Explain the Interview Approach in Prompt Engineering.**\n",
            "\n",
            "The interview approach treats the LLM as if it were a subject in an interview.  The prompt is designed as a series of carefully constructed questions, each building upon the previous one to guide the LLM towards a desired conclusion or answer.  This approach is particularly useful for complex tasks requiring a step-by-step reasoning process.  The interviewer (prompt engineer) controls the flow of information and refines the questions based on the LLM's intermediate answers, similar to a real-life interview. This iterative process helps to refine the LLM's understanding and achieve a more accurate final response.\n",
            "\n",
            "\n",
            "**Q3: Explain Chain-of-Thought (CoT) prompting and its benefits.**\n",
            "\n",
            "Chain-of-Thought (CoT) prompting involves explicitly prompting the LLM to show its reasoning process step-by-step before arriving at a final answer.  Instead of just asking for the answer directly, the prompt encourages the model to articulate its intermediate thoughts, calculations, or logical inferences. For example, instead of asking \"What is 2 + 2 * 4?\", a CoT prompt might say, \"What is 2 + 2 * 4? Let's think step by step.\"  This prompts the LLM to show its working (e.g., \"First, we multiply 2 * 4 = 8. Then, we add 2 + 8 = 10. Therefore, the answer is 10\").\n",
            "\n",
            "Benefits of CoT include:\n",
            "\n",
            "* **Improved accuracy:** By explicitly outlining the reasoning process, the LLM is less likely to make mistakes due to flawed or incomplete reasoning.\n",
            "* **Increased transparency:**  The step-by-step reasoning makes the LLM's output more understandable and interpretable.\n",
            "* **Better handling of complex problems:** CoT allows LLMs to break down complex problems into smaller, more manageable sub-problems.\n",
            "\n",
            "\n",
            "**Q4: Explain Tree-of-Thought (ToT) prompting and how it differs from CoT.**\n",
            "\n",
            "Tree-of-Thought (ToT) prompting extends CoT by exploring multiple reasoning paths simultaneously. Instead of a linear chain, ToT creates a tree-like structure where the LLM explores different possibilities and hypotheses at each step.  It evaluates different approaches concurrently and selects the most promising path based on its intermediate results.  This is especially useful when dealing with problems that have multiple potential solutions or require considering various factors.\n",
            "\n",
            "The key difference between CoT and ToT lies in their search strategy: CoT follows a single path, while ToT explores multiple paths in parallel, enabling more comprehensive and robust problem-solving.\n",
            "\n",
            "\n",
            "**Q5: What are Zero-shot and Few-shot prompting? Compare their applications.**\n",
            "\n",
            "* **Zero-shot prompting:**  The LLM is given a prompt without any examples. The model relies solely on its pre-trained knowledge to generate a response.  This is the simplest approach but often yields less accurate results for complex tasks.  Applications include simple question answering and text generation tasks where the model's general knowledge is sufficient.\n",
            "\n",
            "* **Few-shot prompting:** The LLM is given a few examples of the desired input-output pairs before receiving the actual prompt. These examples provide context and guide the LLM to understand the task better.  This improves accuracy compared to zero-shot prompting.  Applications include tasks requiring specific patterns or styles, such as text summarization, translation, and sentiment analysis.\n",
            "\n",
            "\n",
            "**Q6: Which technique works best for complex problem-solving, and why?**\n",
            "\n",
            "For complex problem-solving, **Tree-of-Thought (ToT)** generally works best.  While Chain-of-Thought improves accuracy over zero-shot and few-shot approaches by forcing a linear reasoning process, ToT significantly enhances this by allowing for exploration of multiple potential solution paths.  Complex problems often involve multiple factors, uncertainties, and potential pitfalls, and the ability to explore different reasoning branches allows ToT to identify more optimal and robust solutions compared to the linear approach of CoT.  The inherent exploration of ToT makes it more resilient to errors and better suited for navigating the intricate pathways required in complex problem-solving scenarios.\n",
            "\n",
            "\n",
            "\n",
            "📝 Chain-of-Thought (CoT):\n",
            "Step 1: The problem states that the farmer \"has 17 sheep\".\n",
            "\n",
            "Step 2:  It then says \"all but 9 run away\".  This means 9 sheep did *not* run away.\n",
            "\n",
            "Step 3: The number of sheep left is the number that did not run away.\n",
            "\n",
            "Step 4: Therefore, there are 9 sheep left.\n",
            "\n",
            "\n",
            "\n",
            "📝 Tree-of-Thought (ToT):\n",
            "## Optimizing Customer Service Chatbot: A Tree-of-Thought Approach\n",
            "\n",
            "**Goal:** Optimize chatbot performance\n",
            "\n",
            "**Potential Solutions:**\n",
            "\n",
            "1. **Improve NLP Understanding:**\n",
            "\n",
            "   * **Pros:**\n",
            "      *  **Increased Accuracy:** (+) Leads to fewer misinterpretations of user queries.\n",
            "         *  (+) Results in more accurate and relevant responses.\n",
            "         *  (+) Reduces user frustration and improves satisfaction.\n",
            "      *  **Wider Range of Queries Handled:** (+) Can handle more complex and nuanced requests.\n",
            "         *  (+) Reduces the need for human intervention.\n",
            "         *  (+) Potentially reduces operational costs.\n",
            "   * **Cons:**\n",
            "      * **High Development Cost:** (-) Requires significant investment in data, algorithms, and expertise.\n",
            "      * **Long Implementation Time:** (-) Training and testing NLP models can be time-consuming.\n",
            "      * **Potential for Bias:** (-)  Trained models can inherit biases present in the training data.\n",
            "\n",
            "\n",
            "2. **Increase Response Speed:**\n",
            "\n",
            "   * **Pros:**\n",
            "      * **Improved User Experience:** (+) Faster responses lead to increased user satisfaction.\n",
            "      * **Increased Efficiency:** (+) Users spend less time waiting for answers.\n",
            "      * **Reduced Abandonment Rate:** (+) Faster responses reduce the likelihood of users leaving before receiving help.\n",
            "   * **Cons:**\n",
            "      * **May Sacrifice Accuracy:** (-)  Prioritizing speed might compromise the quality and accuracy of responses.\n",
            "      * **Technical Challenges:** (-)  Requires optimized infrastructure and efficient algorithms.\n",
            "      * **Limited Impact without other improvements:** (-)  Speed alone won't solve issues stemming from poor NLP.\n",
            "\n",
            "\n",
            "3. **Enhance Personalization:**\n",
            "\n",
            "   * **Pros:**\n",
            "      * **Improved User Engagement:** (+) Personalized interactions create a more positive user experience.\n",
            "      * **Increased Customer Loyalty:** (+) Feeling understood and valued leads to greater customer retention.\n",
            "      * **Targeted Assistance:** (+) Can provide tailored recommendations and solutions based on user history.\n",
            "   * **Cons:**\n",
            "      * **Data Privacy Concerns:** (-) Requires careful handling of user data to comply with regulations.\n",
            "      * **Implementation Complexity:** (-)  Requires integrating user data and implementing personalized logic.\n",
            "      * **Potential for Bias:** (-)  Personalization algorithms can perpetuate biases if not carefully designed.\n",
            "\n",
            "\n",
            "**Reasoning and Choice:**\n",
            "\n",
            "The tree shows that all three solutions offer advantages but also present challenges.  However, considering the long-term impact and overall user experience, **improving NLP understanding (Solution 1)** appears to be the best choice.\n",
            "\n",
            "**Reasoning:**\n",
            "\n",
            "While increased speed (Solution 2) and personalization (Solution 3) are valuable, they are less impactful without accurate understanding. A fast but inaccurate response is frustrating, and personalized but irrelevant responses are equally unhelpful.  A strong NLP foundation will allow for future enhancements in speed and personalization with significantly increased effectiveness. The higher initial investment in NLP improvement will yield greater returns in the long run by addressing the root cause of many chatbot shortcomings.  Addressing potential bias should be a consideration throughout the development and deployment of all three solutions.\n",
            "\n",
            "**Therefore, the recommendation is to prioritize improving NLP understanding, followed by strategies to increase response speed and enhance personalization based on the improved accuracy of the chatbot's understanding.**\n",
            "\n",
            "\n",
            "\n",
            "📝 Zero-Shot Prompting:\n",
            "Le ciel est bleu et le soleil brille.\n",
            "\n",
            "\n",
            "\n",
            "📝 Few-Shot Prompting:\n",
            "Le ciel est bleu et le soleil brille.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}